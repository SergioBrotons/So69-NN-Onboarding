# SIM-06: Before-After KPI Case Analysis

## Section 0 — Metadata

| Field | Value |
|-------|-------|
| **Card_ID** | SIM-06 |
| **Layer** | Simulation |
| **Role_Scope** | All |
| **Critical** | No |
| **Dependencies** | DATA-05 |
| **Version** | v1.0-content |
| **Estimated Duration** | 75 minutes |
| **Difficulty Level** | Advanced |
| **Source Reference** | So69_NN_CARDS_Repository_FULL_v1.0.xlsx |

---

## Section 1 — Strategic Purpose

SIM-06 ensures personnel can analyze before-after KPI cases—demonstrating causal reasoning, controlling for confounding variables, and drawing defensible conclusions from comparative data. This simulation develops the critical ability to prove that interventions actually caused observed changes rather than merely correlating with them.

---

## Section 2 — Foundational Linkage

Builds directly on DATA-05 (Map KPI to Executive Decision), which provides the foundational understanding of how KPIs should connect to business outcomes. Without that foundation, personnel lack the context for understanding whether observed changes represent genuine improvement or statistical artifacts. This simulation tests whether personnel can move from metric understanding to metric analysis.

---

## Section 3 — Core Explanation

### Concept Definition

Before-after analysis compares performance metrics before and after an intervention to determine whether the intervention caused the observed change. This seemingly straightforward approach is fraught with pitfalls—seasonality, external factors, regression to the mean, and other phenomena can create misleading impressions of causal effect when none exists.

### Why This Matters

Business decisions about investments, initiatives, and changes depend on understanding what actually caused results. If the organization cannot distinguish between genuine causal impact and coincidental correlation, resources will be misallocated, successful initiatives will be abandoned, and failed initiatives will be continued.

### The Discipline Requirement

Rigorous before-after analysis requires controlling for alternative explanations, acknowledging limitations, and avoiding over-claiming. The discipline demands intellectual honesty about what the data can and cannot demonstrate. The temptation to claim credit for improvements that may have other causes is a constant threat to analytical integrity.

---

## Section 4 — Scenario

### The Setting

A business unit has implemented a significant operational change and claims strong results based on before-after KPI comparison. Leadership has requested analysis to validate these claims before committing to broader rollout. Personnel must evaluate the evidence, identify potential confounds, and deliver a defensible assessment of whether the intervention actually caused the observed improvement.

### The Challenge

The simulation presents:

- A claimed improvement in a key metric following an intervention
- Additional context data about seasonality, external events, and other factors
- Limited information requiring inference and assumption
- Pressure to either validate or challenge a popular initiative
- Need to communicate findings to non-technical decision-makers

### Data Presentation

The case includes:

- Pre-intervention and post-intervention KPI values
- Historical trend data showing patterns before the intervention
- Information about external factors that may have affected results
- Some data about comparison groups or alternative explanations

---

## Section 5 — Assessment Rubric

The simulation evaluates multiple dimensions of analytical capability:

### Causal Reasoning (30 points)

Personnel must demonstrate understanding of the difference between correlation and causation, articulate alternative explanations for observed changes, and apply appropriate analytical frameworks to evaluate causality claims.

### Variable Identification (20 points)

All relevant confounding variables must be identified—factors other than the intervention that could explain the observed change. Missing important confounds indicates inadequate analysis.

### Evidence Calibration (20 points)

Conclusions must be appropriately hedged based on evidence strength. Over-confident claims about uncertain data, or excessive doubt about clear patterns, both indicate poor calibration.

### Communication Clarity (15 points)

Technical analysis must be translated for non-technical decision-makers. The assessment must clearly communicate findings, confidence level, and implications for decisions.

### Professional Integrity (15 points)

Analysis must be honest even when the conclusions are inconvenient. Protecting a popular initiative by ignoring confounds, or dismissing an unpopular one by exaggerating limitations, represents ethical failure.

**Passing**: 75/100 points with causal reasoning appropriately applied and no critical confounds missed

---

## Section 6 — Failure Modes

### Common Failure Patterns

Personnel frequently fail this simulation through predictable patterns that reveal inadequate analytical discipline.

**Correlation Assumption**: Treating correlation as causation, claiming the intervention caused improvement without controlling for alternative explanations, demonstrates fundamental misunderstanding of causal inference.

**Confound Oversight**: Failing to identify important confounding variables that could explain the observed change indicates incomplete analysis. The obvious confounds must be addressed; missing them is a critical error.

**Cherry-Picking**: Selectively presenting evidence that supports a preferred conclusion while ignoring contradictory data indicates analytical bias. Honest analysis must address all relevant evidence.

**Over-Claiming**: Expressing excessive confidence in uncertain conclusions, or claiming certainty that the data does not support, indicates poor calibration and intellectual dishonesty.

**Translation Failure**: Failing to communicate findings in accessible language, or burying conclusions in technical jargon, means decision-makers cannot act on the analysis.

---

## Section 7 — Success Criteria

### Demonstrated Competencies

Successful completion requires demonstration of the following competencies:

- Clear articulation of causal reasoning principles
- Identification of relevant confounding variables
- Appropriate calibration of confidence based on evidence
- Translation of technical findings for business audience
- Honest assessment even when conclusions are uncomfortable
- Actionable recommendations based on analysis

### Behavioral Indicators

Evaluators look for:

- Explicit discussion of alternative explanations before concluding causation
- Identification of at least three relevant confounding variables
- Appropriate hedging language reflecting evidence limitations
- Clear distinction between what data shows and what it suggests
- Recommendations that follow logically from analysis

---

## Section 8 — Preparation Protocol

### Pre-Simulation Requirements

Before attempting this simulation, personnel must complete:

- Full comprehension of DATA-05 content
- Understanding of basic statistical concepts including correlation, regression, and confounding
- Review of organizational KPIs and their known limitations

### Recommended Preparation Activities

**Causal Inference Training**: Study the principles of causal inference, including counterfactuals, confounding, and experimental design. Understand why simple before-after comparisons can be misleading.

**Case Study Analysis**: Review historical before-after analyses from organizational archives. Identify what was done well and what could be improved.

**Confounding Practice**: For each KPI, generate lists of factors that could affect it independently of interventions. This practice builds the habit of confound identification.

**Communication Practice**: Practice explaining technical analysis to non-technical audiences. The ability to translate is as important as the analysis itself.

---

## Section 9 — Real-World Application

### When This Skill Is Required

Personnel apply these skills in multiple real-world contexts:

- Evaluating marketing campaign effectiveness
- Assessing operational improvement initiatives
- Justifying technology investments
- Analyzing store or regional performance changes
- Reviewing product launch impact
- Determining training program ROI

### Connection to Organizational Decision-Making

Resource allocation depends on understanding what actually works. If the organization cannot distinguish between real impact and statistical noise, investments will be misdirected and successful initiatives may be abandoned. Every strategic decision benefits from rigorous before-after analysis.

---

## Section 10 — LMS MARKDOWN EXPORT

```markdown
# SIM-06: Before-After KPI Case Analysis

## Learning Objectives
- Apply causal reasoning to before-after comparisons
- Identify confounding variables that may explain observed changes
- Calibrate conclusions appropriately based on evidence strength
- Communicate analytical findings to non-technical decision-makers
- Maintain intellectual honesty in the face of pressure

## Prerequisites
- DATA-05: Map KPI to Executive Decision (Required)
- Understanding of basic causal inference principles

## Duration
75 minutes

## Difficulty Level
Advanced

## Assessment
- Passing Score: 75/100 points
- Causal reasoning must be appropriately applied
- No critical confounding variables may be missed

## Content Sections
1. Strategic Purpose
2. Foundational Linkage
3. Core Explanation
4. Scenario
5. Assessment Rubric
6. Failure Modes
7. Success Criteria
8. Preparation Protocol
9. Real-World Application
```
